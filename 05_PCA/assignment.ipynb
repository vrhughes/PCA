{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSYhcVC3h7kj"
      },
      "source": [
        "## PCA and Text Analysis\n",
        "\n",
        "This assignment involves processing real e-mails, some of which are scams. Some of these scam e-mails have some offensive content. I don't think anything is worse than R-rated, but I just want to warn you that if you start reading the e-mail text, you might read something offensive. If that's a problem, feel free to e-mail me and we can talk about it more or you can skip the assignment.  "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://www.github.com/vrhughes/PCA"
      ],
      "metadata": {
        "id": "Ld8-sAepktbk",
        "outputId": "4245fbae-cb3d-41f5-c4db-17ed8b73050f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'PCA'...\n",
            "warning: redirecting to https://github.com/vrhughes/PCA.git/\n",
            "remote: Enumerating objects: 61, done.\u001b[K\n",
            "remote: Counting objects:   4% (1/22)\u001b[K\rremote: Counting objects:   9% (2/22)\u001b[K\rremote: Counting objects:  13% (3/22)\u001b[K\rremote: Counting objects:  18% (4/22)\u001b[K\rremote: Counting objects:  22% (5/22)\u001b[K\rremote: Counting objects:  27% (6/22)\u001b[K\rremote: Counting objects:  31% (7/22)\u001b[K\rremote: Counting objects:  36% (8/22)\u001b[K\rremote: Counting objects:  40% (9/22)\u001b[K\rremote: Counting objects:  45% (10/22)\u001b[K\rremote: Counting objects:  50% (11/22)\u001b[K\rremote: Counting objects:  54% (12/22)\u001b[K\rremote: Counting objects:  59% (13/22)\u001b[K\rremote: Counting objects:  63% (14/22)\u001b[K\rremote: Counting objects:  68% (15/22)\u001b[K\rremote: Counting objects:  72% (16/22)\u001b[K\rremote: Counting objects:  77% (17/22)\u001b[K\rremote: Counting objects:  81% (18/22)\u001b[K\rremote: Counting objects:  86% (19/22)\u001b[K\rremote: Counting objects:  90% (20/22)\u001b[K\rremote: Counting objects:  95% (21/22)\u001b[K\rremote: Counting objects: 100% (22/22)\u001b[K\rremote: Counting objects: 100% (22/22), done.\u001b[K\n",
            "remote: Compressing objects: 100% (17/17), done.\u001b[K\n",
            "remote: Total 61 (delta 12), reused 5 (delta 5), pack-reused 39 (from 1)\u001b[K\n",
            "Receiving objects: 100% (61/61), 2.81 MiB | 14.22 MiB/s, done.\n",
            "Resolving deltas: 100% (17/17), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import all the stuff :)\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "import pickle\n",
        "from collections import Counter\n",
        "from multiprocessing.pool import Pool"
      ],
      "metadata": {
        "id": "BMc9hG61jp_O"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtniyEZ2h7kl"
      },
      "source": [
        "### Q1.\n",
        "\n",
        "Open the `Phishing_Email.parquet` data. It is available at `https://data434.s3.us-east-2.amazonaws.com/Phishing_Email.parquet`, and you can download it directly using Pandas by providing that URL: `df = pd.read_parquet('https://data434.s3.us-east-2.amazonaws.com/Phishing_Email.parquet')`.\n",
        "\n",
        "We just want to look at the first step of cleaning text data, so you can get an idea of how it works. The `Email Text` variable contains the actual text of the email and the `Email Type` takes the value `Phishing Email` or `Safe Email`. We want to predict which emails are phishing emails from their contents.\n",
        "\n",
        "Use the `str.split()` method to break the `Phishing Email` values into **tokens**: The individual words or symbols that create text data like emails. Natural Language Processing is primarily about analyzing the frequency and co-occurrence of tokens. Print the results of your split and examine it.\n",
        "\n",
        "In words, how would you clean the tokens and use them to predict whether the email is a phishing scam or not? A short summary of the kinds of tasks you would do and how you would run a predictive algorithm is fine."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 1\n",
        "# now reading in the parquet data\n",
        "df = pd.read_parquet('https://data434.s3.us-east-2.amazonaws.com/Phishing_Email.parquet')\n",
        "print(df)"
      ],
      "metadata": {
        "id": "mx7D9A6alvgX",
        "outputId": "d12c57be-21dc-463d-9da6-8a95b1d52018",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       index  Unnamed: 0                                         Email Text  \\\n",
            "0          0           0  re : 6 . 1100 , disc : uniformitarianism , re ...   \n",
            "1          1           1  the other side of * galicismos * * galicismo *...   \n",
            "2          2           2  re : equistar deal tickets are you still avail...   \n",
            "3          3           3  \\nHello I am your hot lil horny toy.\\n    I am...   \n",
            "4          4           4  software at incredibly low prices ( 86 % lower...   \n",
            "...      ...         ...                                                ...   \n",
            "18629  18645       18646  date a lonely housewife always wanted to date ...   \n",
            "18630  18646       18647  request submitted : access request for anita ....   \n",
            "18631  18647       18648  re : important - prc mtg hi dorn & john , as y...   \n",
            "18632  18648       18649  press clippings - letter on californian utilit...   \n",
            "18633  18649       18650                                              empty   \n",
            "\n",
            "           Email Type  \n",
            "0          Safe Email  \n",
            "1          Safe Email  \n",
            "2          Safe Email  \n",
            "3      Phishing Email  \n",
            "4      Phishing Email  \n",
            "...               ...  \n",
            "18629  Phishing Email  \n",
            "18630      Safe Email  \n",
            "18631      Safe Email  \n",
            "18632      Safe Email  \n",
            "18633  Phishing Email  \n",
            "\n",
            "[18634 rows x 4 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 1\n",
        "# spliting the email values into tokens\n",
        "tokens = df['Email Text'].str.split()\n",
        "\n",
        "tokens.head()"
      ],
      "metadata": {
        "id": "88GDzjHGmhm9",
        "outputId": "5058b7bc-b207-41fe-f526-0f822703eaac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [re, :, 6, ., 1100, ,, disc, :, uniformitarian...\n",
              "1    [the, other, side, of, *, galicismos, *, *, ga...\n",
              "2    [re, :, equistar, deal, tickets, are, you, sti...\n",
              "3    [Hello, I, am, your, hot, lil, horny, toy., I,...\n",
              "4    [software, at, incredibly, low, prices, (, 86,...\n",
              "Name: Email Text, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Email Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[re, :, 6, ., 1100, ,, disc, :, uniformitarian...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[the, other, side, of, *, galicismos, *, *, ga...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[re, :, equistar, deal, tickets, are, you, sti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[Hello, I, am, your, hot, lil, horny, toy., I,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[software, at, incredibly, low, prices, (, 86,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 1\n",
        "# cleaning the data\n",
        "import string\n",
        "\n",
        "# remove punctuation from the tokens\n",
        "for email in tokens:\n",
        "   for i in range(len(email)):\n",
        "      email[i] = email[i].translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "tokens.head()\n"
      ],
      "metadata": {
        "id": "W0SmLnSooarF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "94982c91-fa22-4b73-950a-adf0a2c48d8f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [re, , 6, , 1100, , disc, , uniformitarianism,...\n",
              "1    [the, other, side, of, , galicismos, , , galic...\n",
              "2    [re, , equistar, deal, tickets, are, you, stil...\n",
              "3    [Hello, I, am, your, hot, lil, horny, toy, I, ...\n",
              "4    [software, at, incredibly, low, prices, , 86, ...\n",
              "Name: Email Text, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Email Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[re, , 6, , 1100, , disc, , uniformitarianism,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[the, other, side, of, , galicismos, , , galic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[re, , equistar, deal, tickets, are, you, stil...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[Hello, I, am, your, hot, lil, horny, toy, I, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[software, at, incredibly, low, prices, , 86, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 1:\n",
        "\n",
        "In order to clean the tokens I would remove punctuation (as seen above) and then I would clear those empty spaced in the tokens series. After that I would probably try and make a list of buzz words like \"deal\", \"prices\", \"click\", \"hot\", etc that commonly occur in phishing emails and see if they appear in an email. If only one word occurs, that could just be a coincidence (business email addressing prices), but if multiple buzzwords show up in an email I would then sort those into another category called potential phishing or something along those lines."
      ],
      "metadata": {
        "id": "sa7N6ws-sCTk"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pifmEH5nh7kl"
      },
      "source": [
        "### Q2.\n",
        "\n",
        "I aggregated all the emails into a single vector, and removed the punctuation and very common words (e.g. \"the\"). Run the below code chunk to open it, and use the Counter class to look at the most common words:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "IDVERVo4h7kl"
      },
      "outputs": [],
      "source": [
        "with open('/content/PCA/05_PCA/all_tokens.pickle', 'rb') as file:\n",
        "    all_tokens = pickle.load(file)\n",
        "\n",
        "from collections import Counter\n",
        "token_count = Counter(all_tokens)\n",
        "token_freq = token_count.most_common()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upG-0hd1h7km"
      },
      "source": [
        "Plot a histogram of the occurrences of tokens. What do you notice about the frequency of occurrence of different tokens? How does it look?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_occurences = pd.DataFrame(token_freq,columns=['token','count'])\n",
        "token_occurences['count'].hist(grid=False,bins=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "hUtwePMErMYp",
        "outputId": "1e1d841c-f9c0-4c21-e4ef-e8b34102297b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The large majority of tokens do not occur frequently (most occur once, only a few even occur twice), however there is a token that is clearly incredibly common (which is messing up my y axis)."
      ],
      "metadata": {
        "id": "lVBCB04KrytU"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FH_HaE5Zh7kn"
      },
      "source": [
        "### Q3.\n",
        "\n",
        "Load `Phishing_clean.parquet`. This is the text from the e-mails broken into the most common 2,711 tokens and one-hot-encoded as features/covariates. So each row is an e-mail, the `Email Type` takes the value 1 if it's a scam and 0 otherwise, and every other column is a word or symbol that occurs in at least 15 e-mails.\n",
        "\n",
        "1. Perform an 80/20 train-test split of the data.\n",
        "2. Run a regression of $y$ on the one-hot-encoded emails. What is the $R^2$ on the test set? On the training set?\n",
        "3. What words have the largest coefficients in absolute value and most strongly influence predictions?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 3\n",
        "clean = pd.read_parquet('/content/PCA/05_PCA/Phishing_clean.parquet')\n",
        "\n",
        "y = df['Email Type']\n",
        "X = df.drop('Email Type', axis=1)"
      ],
      "metadata": {
        "id": "vS1MA6cxsTqw"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 3\n",
        "# train-test split and linear regression\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=125)\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_hat_test = model.predict(X_test)\n",
        "y_hat_train = model.predict(X_train)\n",
        "\n",
        "r_squared_train = model.score(X_train, y_train)\n",
        "r_squared_test = model.score(X_test, y_test)\n",
        "\n",
        "print(f\"R^2 on the training set: {r_squared_train}\")\n",
        "print(f\"R^2 on the test set: {r_squared_test}\")\n",
        "\n",
        "lm_0 = LinearRegression(fit_intercept=False).fit(X_train ,y_train)\n",
        "y_hat_test_0 = lm_0.predict(X_test)\n",
        "y_hat_train_0 = lm_0.predict(X_train)\n",
        "print('Train: ', r2_score(y_hat_train, y_train) )\n",
        "print('Test: ', r2_score(y_hat_test, y_test) )"
      ],
      "metadata": {
        "id": "RAVHgXG-skjs",
        "outputId": "5c3511e0-135b-4f82-fe3b-79d527d09e69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 651
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "could not convert string to float: 'Kevin wrote:\\n> am i the only one who thinks this is like \"friday night 80\\'s\" for ilug?\\n> and here\\'s an answer from 1989.  for those perceptive folks in the\\n> audience you\\'ll note that it makes no reference to a windows icons.> so yeah, unrm would be nice, but obviously it\\'s not a simple problem.\\n> millions of lines of code, hundreds of projects, no unrm.  heck, the\\n> hurd will probably release 1.0 before unrm shows up.So what this tells us is:\\n1) There are very few new ideas.\\n2) Problems exists until someone gets annoyed enough to actually fix them\\nrather than find bizarre ways to solve the problem.\\n3) I have too much creative time on my hands with not enough productive\\ntime.>>From which we can infer that no work on unrm will be happening on my\\ncomputer for a long time.:)- Matthew\\n__________________________________________________\\nDo You Yahoo!?\\nEverything you\\'ll ever need on one web page\\nfrom News and Sport to Email and Music Charts\\nhttp://uk.my.yahoo.comm\\n-- \\nIrish Linux Users\\' Group: ilug@linux.ie\\nhttp://www.linux.ie/mailman/listinfo/ilug for (un)subscription information.\\nList maintainer: listmaster@linux.ie\\n'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-99cb05b55ae6>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m125\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mlm_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfit_intercept\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0my_hat_test_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlm_0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0my_hat_train_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlm_0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1471\u001b[0m                 )\n\u001b[1;32m   1472\u001b[0m             ):\n\u001b[0;32m-> 1473\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1475\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[0maccept_sparse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpositive\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"coo\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 609\u001b[0;31m         X, y = self._validate_data(\n\u001b[0m\u001b[1;32m    610\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    648\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 650\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    651\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1299\u001b[0m         )\n\u001b[1;32m   1300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1301\u001b[0;31m     X = check_array(\n\u001b[0m\u001b[1;32m   1302\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1010\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1012\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m                 raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp, device)\u001b[0m\n\u001b[1;32m    743\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 745\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    746\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m         \u001b[0;31m# At this point array is a NumPy ndarray. We convert it to an array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype, copy)\u001b[0m\n\u001b[1;32m   2151\u001b[0m     ) -> np.ndarray:\n\u001b[1;32m   2152\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2153\u001b[0;31m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2154\u001b[0m         if (\n\u001b[1;32m   2155\u001b[0m             \u001b[0mastype_is_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Kevin wrote:\\n> am i the only one who thinks this is like \"friday night 80\\'s\" for ilug?\\n> and here\\'s an answer from 1989.  for those perceptive folks in the\\n> audience you\\'ll note that it makes no reference to a windows icons.> so yeah, unrm would be nice, but obviously it\\'s not a simple problem.\\n> millions of lines of code, hundreds of projects, no unrm.  heck, the\\n> hurd will probably release 1.0 before unrm shows up.So what this tells us is:\\n1) There are very few new ideas.\\n2) Problems exists until someone gets annoyed enough to actually fix them\\nrather than find bizarre ways to solve the problem.\\n3) I have too much creative time on my hands with not enough productive\\ntime.>>From which we can infer that no work on unrm will be happening on my\\ncomputer for a long time.:)- Matthew\\n__________________________________________________\\nDo You Yahoo!?\\nEverything you\\'ll ever need on one web page\\nfrom News and Sport to Email and Music Charts\\nhttp://uk.my.yahoo.comm\\n-- \\nIrish Linux Users\\' Group: ilug@linux.ie\\nhttp://www.linux.ie/mailman/listinfo/ilug for (un)subscription information.\\nList maintainer: listmaster@linux.ie\\n'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWhf2WvDh7kn"
      },
      "source": [
        "### Q4.\n",
        "\n",
        "Take the matrix of one-hot-encoded tokens (the data, less the outcome variable, `Email Type`) and perform a principal components analysis decomposition with two components. Plot the first two principal components in a scatter plot, and hue the points by whether they are a phishing scam or not. Do you notice any patterns?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDo4dbV-h7kn"
      },
      "source": [
        "### Q5.\n",
        "\n",
        "Run a linear regression of $y$ on the first 2,610 principal components of $X$. What is the $R^2$ on the training and test sets? (I used cross validation to determine that 2,610 was approximately optimal, but not all 2,711 components.)\n",
        "\n",
        "How does this performance compare to the linear regression?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4VP1Sb0h7ko"
      },
      "source": [
        "### Q6.\n",
        "\n",
        "Explain briefly in your own words what the advantage is in using the principal components to run this high-dimensional regression, rather than the original data."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".txt",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}